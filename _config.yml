# Site
repository: yinshuo-thu/yinshuo-thu.github.io
# favicon: Directory of your favicon (eg. images/favicon.ico)(optional)

# Content configuration version
version: 2

# Personal info
name: Shuo Yin
title: Quantitative Researcher & ML Engineer
email: yins25@mails.tsinghua.edu.cn
# email_title: Email (Email title override)
phone: (+86) 15690129730
# phone_title: Phone (Phone title override)
website: https://yinshuo-thu.github.io
# website_title: Web (Website title override)

# Dark Mode (true/false/never)
darkmode: false

# Social links
twitter_username: 
github_username: yinshuo156
stackoverflow_username: 
dribbble_username: 
facebook_username: 
flickr_username: 
instagram_username: 
linkedin_username: shuoyin
xing_username: 
pinterest_username: 
youtube_username: 
orcid_username: 
googlescholar_username:

# Additional icon links
additional_links:
- title: Link name
  icon: Font Awesome brand icon name (eg. fab fa-twitter) (https://fontawesome.com/icons?d=gallery&s=brands&m=free)
  url: Link url (eg. https://google.com)
# - title: another link
#   icon: font awesome brand icon name (eg. fab fa-twitter) (https://fontawesome.com/icons?d=gallery&s=brands&m=free)
#   url: Link url (eg. https://google.com)

# Google Analytics and Tag Manager
# Using more than one of these may cause issues with reporting
# gtm: "GTM-0000000"
# gtag: "UA-00000000-0"
# google_analytics: "UA-00000000-0"

# About Section
# about_title: About Me (Use this to override about section title)
about_profile_image: images/profile.jpg
about_content: | # this will include new lines to allow paragraphs
  I am a Master's student in Finance at Tsinghua University with a strong background in Biomedical Engineering from Shanghai Jiao Tong University. My research focuses on **quantitative finance**, **machine learning**, and **large language models**, with particular expertise in developing algorithmic trading strategies and financial time series forecasting.

  Currently working as a Quantitative Research Intern at Lingjun Investment (¥40B AUM), I specialize in building cross-sectional and time-series ML models for equity trading. My work spans from traditional machine learning approaches like LightGBM and MLP to advanced deep learning architectures including GRU and Transformer models, achieving significant alpha generation with Sharpe ratios exceeding 2.0.

  I have extensive experience in **LLM research and development**, having contributed to projects at Ant Group (Alipay) where I engineered the ProQ model for automated data screening. My research contributions include publications in top-tier venues (AAAI, ICLR) and ongoing work on multimodal LLM evaluation methods.

  My technical expertise encompasses Python, C++, SQL, and various ML frameworks, with a proven track record in both academic research and industry applications. I am passionate about bridging the gap between cutting-edge AI research and practical financial applications.

content:
  - title: Education
    layout: list
    content:
      - layout: top-right
        title: Tsinghua University, School of Economics and Management
        sub_title: Master of Finance
        caption: Sept 2025 - Jun 2027
        quote: >
          Beijing, China
        description: | # this will include new lines to allow paragraphs
          **Current Courses:** Large Language Models and Generative AI, Financial Derivatives, Financial Data Analysis, Introduction to FinTech
          
          **Research Focus:** Quantitative finance, algorithmic trading, and machine learning applications in financial markets
      - layout: top-right
        title: Shanghai Jiao Tong University, School of Biomedical Engineering
        sub_title: Bachelor of Engineering (Electronic & Computer Eng. Track)
        caption: Sept 2021 - Jun 2025
        quote: >
          Shanghai, China
        description: | # this will include new lines to allow paragraphs
          **GPA:** 3.75/4.0 | Merit Student Award | First Class Academic Scholarship | Outstanding Graduate
          
          **Core Courses:** Data Structure (A), Methods in Mathematical Physics (A), Biostatistics (A-), Medical Robot Control (A)
          
          **Research:** Multimodal LLM (AAAI, ICLR); Financial Time Series (SCI Q2 journal); Agent, Reinforcement Learning (CCF-B conf.)
  - title: Internship
    layout: list
    content:
      - layout: right
        title: Lingjun Investment (AUM ¥40B Chinese Quant)
        sub_title: Quantitative Research Intern
        caption: Aug 2025 - Present
        link: 
        quote: >
          Beijing, China
        description: | # this will include new lines to allow paragraphs
          **Machine Learning Cross-Sectional Model:** Built LightGBM and MLP models to predict cross-sectional returns
          - LightGBM: Trained on 1k+ alpha factors with rolling windows; 2021–2023 backtest (long top-30%) hit 42% AR, Sharpe 2.25, max DD −8.8%; 2025 live-simulated trading, AR 30%+ after portfolio optimization
          - MLP: Designed and tuned MLP with rolling predictions; 2021–2023 backtest top-30% long portfolio achieved AR 48.2%, Sharpe 2.48, max drawdown −10.5%; recent live-simulated trading shows 40%+ annualized
          
          **Deep Learning Time Series Strategy:** Developed GRU and Transformer baselines, with MoE combination attempts
          - GRU: Added input-projection block (Linear → LayerNorm → GELU), followed by bidirectional GRU encoder and temporal-attention pooling; loss-driven optimization improved backtest AR by 2%+ to 57%
          - Transformer: Implemented encoder-only Transformer with linear feature mapping and sinusoidal positional encoding; currently developing multi-scale temporal fusion; baseline backtest AR 44%
      - layout: right
        title: Ant Group (Alipay)
        sub_title: LLM Algorithm Intern
        caption: Apr 2025 - Aug 2025
        link: 
        quote: >
          Shanghai, China
        description: | # this will include new lines to allow paragraphs
          Engineered ProQ model for automated data screening on Ling LLM; fine-tuned quality-filtering LLMs and streamlined the pipeline
          
          **Data Screening Model:** Built custom agent-based data screening and harmonization model (ProQ), pre-screening data using metrics like PPL and iteratively selecting representative data for fine-tuning quality-filtering models. Post-trained Ling MOE Lite on ~3M optimized data, improving language understanding and code completion by over 1%
          
          **Signal-Based Data Filters:** Developed rule- and model-based operators to identify low-quality data using targeted signals
      - layout: right
        title: Panoramic Hills Capital (AUM $4B Hedge Fund)
        sub_title: Crypto Research Intern
        caption: Jan 2025 - Mar 2025
        link: 
        quote: >
          Shanghai, China
        description: | # this will include new lines to allow paragraphs
          Conducted crypto market monitoring and developed sentiment indices on crypto, providing insights for fund positioning
          
          **NLP Sentiment Index Modeling:** Built scrapers and real-time pipelines to source, aggregate, and filter crypto feeds; fine-tuned BERT sentiment model on collected data to produce index used to guide position sizing
          
          **Crypto Analysis:** Monitored daily crypto trends; constructed financial models for BTC miners (MARA, CLSK, RIOT, etc.)
  - title: Research & Publications
    layout: list # Type of content section (list/text)
    content:
      - layout: left
        border: weak
        title: "AlphaMaster: Comprehensive Alpha Discovery and Agent Implementation"
        link: https://github.com/yinshuo156/AlphaMaster
        link_text: GitHub Repository
        additional_links:
          - title: GitHub Repository
            icon: fab fa-github
            url: https://github.com/yinshuo156/AlphaMaster
        quote: >
          Aug 2025 - Present
        description: | # this will include new lines to allow paragraphs
          Applied machine learning–based quantitative modeling methods to refine equity strategies (MLP, GRU, Transformer)
          
          **Multi-source factor generation:** Integrated Agents, Genetic Algorithms, and Flow Networks to produce diversified alpha factors
          - Flow Networks: Added structure-aware encoder with RGCN to capture mathematical relations; used flow-network exploration with dense, multi-aspect rewards to generate diverse, stable, and efficient alpha candidates
          - Agent pipeline: Employed multi-agent discovery for interpretable, decay-resistant factors; leveraged Qlib for hypothesis formation, factor construction, and walk-forward backtesting to validate efficacy
          - Genetic algorithm: Encoded factor expressions and applied crossover/mutation; selected robust factors using quantitative metrics
          
          **Factor alignment & Alpha reports:** Developed factor alignment and filtering framework for A-shares and cryptocurrencies, implementing data cleansing, dual-chain dynamic iteration, and agent-based reporting
      - layout: left
        border: weak
        title: "TS-Agent: RL Empowered LLM Agents for Financial Time Series Forecasting"
        link: https://github.com/yinshuo156/TS-Agent
        link_text: GitHub Repository
        additional_links:
          - title: GitHub Repository
            icon: fab fa-github
            url: https://github.com/yinshuo156/TS-Agent
        quote: >
          Jun 2025 - Sept 2025
        description: | # this will include new lines to allow paragraphs
          Developed TS-Agent, a reinforcement learning–based agent for financial time-series forecasting, using LLM-generated strategy pool for exploration-enhanced fine-tuning, then seeding stepwise RL from selected strategies with custom RL module
          
          Improved strategy generation beyond baseline by over 10%, with strategy performance close to top-tier LLMs (e.g., DeepSeek-R1)
      - layout: left
        border: weak
        title: "ProQ: Automated Data Screening Framework for LLM Training"
        link: 
        link_text: 
        additional_links:
        quote: >
          Apr 2025 - Aug 2025
        description: | # this will include new lines to allow paragraphs
          Engineered comprehensive data screening and harmonization framework for large language model training
          
          **Agent-based Workflow:** Designed custom agent-based data screening pipeline with iterative quality assessment and representative data selection
          
          **Performance Optimization:** Post-trained Ling MOE Lite on ~3M optimized data, improving language understanding and code completion by over 1%
      - layout: left
        border: weak
        title: LNG Freight Rate Multifractal Analysis and Trading Strategy
        link: https://github.com/yinshuo156/Code_LNG
        link_text: GitHub Repository
        additional_links:
          - title: GitHub Repository
            icon: fab fa-github
            url: https://github.com/yinshuo156/Code_LNG
          - title: Published Paper
            icon: fas fa-file-alt
            url: https://link.springer.com/article/10.1007/s11071-024-10343-1
        quote: >
          Feb 2024 - Sept 2024
        description: | # this will include new lines to allow paragraphs
          Conducted comprehensive multifractal analysis of LNG spot freight rates and developed predictive models with trading strategies
          
          **Published in Nonlinear Dynamics (SCI Q2):** Complete implementation of prediction models and quantitative trading strategies
          
          **Technical Implementation:** ~5k lines of code covering multifractal analysis, time series prediction, and portfolio optimization
      - layout: left
        border: weak
        title: "Kaggle Competition: Optiver Trading at the Close (Bronze Medalist)"
        link: 
        link_text: 
        additional_links:
        quote: >
          Sep 2023 - Mar 2024
        description: | # this will include new lines to allow paragraphs
          Built LightGBM-based predictive model, forecasting Nasdaq stock closing price movements from order book and auction data
          
          **Technical Approach:** Implemented purged time-series cross-validation to mitigate lookahead bias, applied hyperparameter tuning with early stopping, and retrained final ensemble model
          
          **Results:** Achieved Mean Absolute Error (MAE) of 5.473 on validation, earning Bronze Medal ranking
  - title: Skills & Additional Information
    layout: text
    content: | # this will include new lines to allow paragraphs
      ## Technical Skills
      - **Programming Languages:** Python, C++, SQL
      - **Development Tools:** Git, Wind Terminal, Excel/PowerPoint
      - **Machine Learning:** LightGBM, PyTorch, TensorFlow, Scikit-learn
      - **Quantitative Finance:** Qlib, PyPortfolioOpt, Alphalens, Backtrader
      - **Data Analysis:** Pandas, NumPy, Matplotlib, Seaborn
      - **Deep Learning:** Transformer, GRU, LSTM, CNN, RNN
      - **Natural Language Processing:** BERT, GPT, LLM fine-tuning
      - **Cloud & Deployment:** Docker, Linux, CentOS

      ## Language Proficiency
      - **English:** TOEFL 108, Professional Working Proficiency
      - **Chinese:** Native Speaker

      ## Hobbies & Interests
      - **Basketball:** Vice Captain of College Team, Center/Power Forward position
      - **Go (Weiqi):** Strategic board game enthusiast
      - **Tennis:** Recreational player
      - **Research:** Passionate about quantitative finance and AI applications in financial markets

# Footer
footer_show_references: true
# references_title: References on request (Override references text)

# Build settings
# theme: modern-resume-theme (Use this is you are hosting your resume yourself)
remote_theme: sproogen/modern-resume-theme

# GitHub Pages settings
baseurl: "" # the subpath of your site, e.g. /blog
url: "https://yinshuo-thu.github.io" # the base hostname & protocol for your site

sass:
  sass_dir: _sass
  style: compressed

plugins:
 - jekyll-seo-tag

exclude : [
  "Gemfile",
  "Gemfile.lock",
  "node_modules",
  "vendor/bundle/",
  "vendor/cache/",
  "vendor/gems/",
  "vendor/ruby/",
  "lib/",
  "scripts/",
  "docker-compose.yml",
  ]
